{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaging-warehouse",
   "metadata": {},
   "source": [
    "## Polynomial Sequence to Sequence Encoder\n",
    "\n",
    "In this notebook I am exploring building a sequence-to-sequence encoder that will accept as input a factored polynomial and predict the expanded version based on input characters (not a mathematical scheme).\n",
    "\n",
    "My pre-processing steps include splitting sequences to individual characters, tokenization,  identifier vectorization and implementing padding to target sequences.\n",
    "\n",
    "The model architecture used is an Encoder-Decoder network with three LSTM layers in the Encoder and 1 LSTM layer in the Decoder. I use a sparse catagorical cross-entropy loss function and Adam optimizer.\n",
    "\n",
    "I am currently working on implementation of the inference model which successfully translates the decoder output to the expanded polynomial string, but have saved the trained model (model trained on data in file entitled \"data.txt\") as \"seq2seq_2_trained.h5\". This was the second model architecture explored, the first model architecture, trained on the same data, was saved as \"seq2seq_trained.h5\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genuine-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences, to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-slope",
   "metadata": {},
   "source": [
    "### Load in and prepare the data\n",
    "\n",
    "We are going to be dealing with an input sequence of characters and an output sequence of characters (of different lengths). The input sequences will be factored formes of polynomials while the output (target) sequences will be the expanded forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factored</th>\n",
       "      <th>expanded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(7-3*z)*(-5*z-9)</td>\n",
       "      <td>15*z**2-8*z-63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9*s**2</td>\n",
       "      <td>-9*s**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2-2*n)*(n-1)</td>\n",
       "      <td>-2*n**2+4*n-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x**2</td>\n",
       "      <td>x**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4-x)*(x-23)</td>\n",
       "      <td>-x**2+27*x-92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           factored        expanded\n",
       "0  (7-3*z)*(-5*z-9)  15*z**2-8*z-63\n",
       "1           -9*s**2         -9*s**2\n",
       "2     (2-2*n)*(n-1)   -2*n**2+4*n-2\n",
       "3              x**2            x**2\n",
       "4      (4-x)*(x-23)   -x**2+27*x-92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"data.txt\", sep=\"=\", header=None)\n",
    "data.columns=[\"factored\", \"expanded\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seeing-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 2)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "#just to speed things along lets let the data set be just 2000 pairs long\n",
    "print(data.shape)\n",
    "data = data.iloc[:10000,:]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fewer-butterfly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factored</th>\n",
       "      <th>expanded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(, 7, -, 3, *, z, ), *, (, -, 5, *, z, -, 9, )]</td>\n",
       "      <td>[1, 5, *, z, *, *, 2, -, 8, *, z, -, 6, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-, 9, *, s, *, *, 2]</td>\n",
       "      <td>[-, 9, *, s, *, *, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(, 2, -, 2, *, n, ), *, (, n, -, 1, )]</td>\n",
       "      <td>[-, 2, *, n, *, *, 2, +, 4, *, n, -, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[x, *, *, 2]</td>\n",
       "      <td>[x, *, *, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(, 4, -, x, ), *, (, x, -, 2, 3, )]</td>\n",
       "      <td>[-, x, *, *, 2, +, 2, 7, *, x, -, 9, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           factored  \\\n",
       "0  [(, 7, -, 3, *, z, ), *, (, -, 5, *, z, -, 9, )]   \n",
       "1                             [-, 9, *, s, *, *, 2]   \n",
       "2           [(, 2, -, 2, *, n, ), *, (, n, -, 1, )]   \n",
       "3                                      [x, *, *, 2]   \n",
       "4              [(, 4, -, x, ), *, (, x, -, 2, 3, )]   \n",
       "\n",
       "                                     expanded  \n",
       "0  [1, 5, *, z, *, *, 2, -, 8, *, z, -, 6, 3]  \n",
       "1                       [-, 9, *, s, *, *, 2]  \n",
       "2     [-, 2, *, n, *, *, 2, +, 4, *, n, -, 2]  \n",
       "3                                [x, *, *, 2]  \n",
       "4     [-, x, *, *, 2, +, 2, 7, *, x, -, 9, 2]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the sequences into a list each of characters\n",
    "def seq_splitter(seq):\n",
    "    char_list = list(seq)\n",
    "    return char_list\n",
    "\n",
    "#apply it to the data frame\n",
    "data.factored = data.factored.apply(lambda x: seq_splitter(x))\n",
    "\n",
    "data.expanded = data.expanded.apply(lambda x: seq_splitter(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "operating-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "#what is the maximum length of the input sentences\n",
    "MAX_LEN= max(list(map(lambda x: len(x), data.factored)))\n",
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "negative-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a <BOS> (Beginning of Sequence) and <EOS> (End of Sequence) tag to the sequences for decoder input\n",
    "def tagger(decoder_input_sequence):\n",
    "    bos = \"<BOS>\"\n",
    "    eos = \"<EOS>\"\n",
    "    for seq in decoder_input_sequence:\n",
    "        seq.insert(0,bos)\n",
    "        seq.append(eos)\n",
    "#     final_target = [seq.insert(0,bos) + seq + eos for seq in decoder_input_sequence]\n",
    "    return decoder_input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "commercial-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag the beginning and end of the expansions sequences\n",
    "expansions = tagger(data.expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "civic-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define the vocabulary, determine size of one-hot encoded sequence vector\n",
    "# #the vocabulary will be a collection of characters in this context, not words\n",
    "\n",
    "VOCAB_SIZE = 31 # adding 2+29 for <BOS> and <EOS> tags not sure if this is correct- Sofia come back to this...\n",
    "\n",
    "def vocab_creator(seq_lists, VOCAB_SIZE):\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words = VOCAB_SIZE)\n",
    "    tokenizer.fit_on_texts(seq_lists)\n",
    "    dictionary = tokenizer.word_index\n",
    "    \n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    \n",
    "    for i, j in dictionary.items():\n",
    "        \n",
    "        if j < VOCAB_SIZE:\n",
    "            word2idx[i] = j\n",
    "            idx2word[j] = i\n",
    "            \n",
    "        if j >= VOCAB_SIZE-1:\n",
    "            continue\n",
    "    \n",
    "    return word2idx, idx2word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "expected-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input_text = data.factored\n",
    "word2idx, idx2word = vocab_creator(seq_lists = factors + expansions, VOCAB_SIZE=VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "invisible-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'*': 1, '-': 2, '2': 3, '(': 4, ')': 5, '1': 6, '+': 7, '<bos>': 8, '<eos>': 9, '4': 10, '3': 11, '6': 12, '8': 13, '5': 14, '7': 15, '0': 16, 'n': 17, 's': 18, 'i': 19, '9': 20, 'o': 21, 'a': 22, 't': 23, 'c': 24, 'k': 25, 'x': 26, 'z': 27, 'y': 28, 'h': 29, 'j': 30}\n",
      "{1: '*', 2: '-', 3: '2', 4: '(', 5: ')', 6: '1', 7: '+', 8: '<bos>', 9: '<eos>', 10: '4', 11: '3', 12: '6', 13: '8', 14: '5', 15: '7', 16: '0', 17: 'n', 18: 's', 19: 'i', 20: '9', 21: 'o', 22: 'a', 23: 't', 24: 'c', 25: 'k', 26: 'x', 27: 'z', 28: 'y', 29: 'h', 30: 'j'}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)\n",
    "print(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tight-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the factored sequences\n",
    "factors = data.factored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "short-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now tokenize the bag of words to a bag of IDs- transform each sequence of characters into sequences of ids\n",
    "def text2seq(factors, expansions, VOCAB_SIZE):\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words = VOCAB_SIZE)\n",
    "    tokenizer.fit_on_texts(factors + expansions)\n",
    "    factor_sequences = tokenizer.texts_to_sequences(factors)\n",
    "    expansion_sequences = tokenizer.texts_to_sequences(expansions)\n",
    "    \n",
    "    return factor_sequences, expansion_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "infinite-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_sequences, expansion_sequences = text2seq(factors, expansions, VOCAB_SIZE=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "suffering-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now implement padding to the sequences- use the max sequence length we found earlier\n",
    "#(we expect the max encoder input length to be < the max decoder input length)\n",
    "\n",
    "def padding(factor_sequences, expansion_sequences, MAX_LEN):\n",
    "    \n",
    "    factors_padded = pad_sequences(factor_sequences, maxlen = MAX_LEN, padding = 'post', truncating = 'post')\n",
    "    expansions_padded = pad_sequences(expansion_sequences, maxlen = MAX_LEN, padding = 'post', truncating = 'post')\n",
    "    \n",
    "    return factors_padded, expansions_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fifty-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_padded, expansions_padded = padding(factor_sequences, expansion_sequences, MAX_LEN=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-laser",
   "metadata": {},
   "source": [
    "### Now define the model architecture and train!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "northern-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seq2seq_model(HIDDEN_DIM=300, EMBEDDING_DIM=10):\n",
    "    \n",
    "#     #first the encoder layers\n",
    "#     encoder_inputs = Input(shape = (MAX_LEN, ), \n",
    "#                            dtype = 'int32')\n",
    "#     embed_layer = Embedding(input_dim = VOCAB_SIZE,\n",
    "#                            output_dim = EMBEDDING_DIM,\n",
    "#                            input_length = MAX_LEN)\n",
    "#     encoder_embedding = embed_layer(encoder_inputs) #sofia what is embed_layer() doing?\n",
    "#     encoder_LSTM = LSTM(HIDDEN_DIM,\n",
    "#                        return_state = True)\n",
    "#     encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "    \n",
    "#     #now the decoder layers\n",
    "#     decoder_inputs = Input(shape = (MAX_LEN, ), \n",
    "#                           dtype = 'int32')\n",
    "#     decoder_embedding = embed_layer(decoder_inputs)\n",
    "#     decoder_LSTM = LSTM(HIDDEN_DIM, \n",
    "#                        return_state = True, \n",
    "#                        return_sequences = True)\n",
    "#     #setting the initial state of the LSTM layer as the final state of the encoder LSTM layer\n",
    "#     decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
    "    \n",
    "#     #the final Dense layer ( applying a layer to every temporal input slice )\n",
    "#     outputs = TimeDistributed(Dense(VOCAB_SIZE, activation = 'softmax'))(decoder_outputs)\n",
    "#     model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "timely-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = seq2seq_model(HIDDEN_DIM=20)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sporting-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #now let's train the model!!\n",
    "\n",
    "# model.compile(optimizer = 'adam',\n",
    "#              loss = 'categorical_crossentropy',\n",
    "#              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "imported-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_in_train, en_in_test, de_in_train, de_in_test, de_out_train, de_out_test = train_test_split(encoder_input_data, decoder_input_data, decoder_output_data, test_size=0.3)\n",
    "# print(en_in_train.shape, de_in_train.shape, de_out_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "seeing-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 700\n",
    "# EPOCHS = 5 #lets start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "first-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make sure to save the training progress\n",
    "# history = model.fit([en_in_train, de_in_train], de_out_train,\n",
    "#                    epochs = EPOCHS, \n",
    "#                    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-highlight",
   "metadata": {},
   "source": [
    "### Let's save the model and visualize the learning history!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "respected-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 29)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 29, 10)       310         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, 29, 300),    373200      ['embedding_2[0][0]']            \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 10)     310         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  [(None, 29, 300),    721200      ['lstm_4[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  [(None, None, 300),  373200      ['embedding_3[0][0]',            \n",
      "                                 (None, 300),                     'lstm_6[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_6[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 31)    9331        ['lstm_7[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,477,551\n",
      "Trainable params: 1,477,551\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 300\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape = (MAX_LEN,))\n",
    "\n",
    "#Embedding layer\n",
    "enc_emb = Embedding(input_dim = VOCAB_SIZE,\n",
    "                    output_dim = EMBEDDING_DIM,\n",
    "                    input_length = MAX_LEN,\n",
    "                   trainable = True)(encoder_inputs)\n",
    "\n",
    "#Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(HIDDEN_DIM, \n",
    "                    return_sequences = True,\n",
    "                    return_state = True, \n",
    "                    dropout = 0.4, \n",
    "                    recurrent_dropout = 0.4)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "#ENcoder LSTM 2\n",
    "encoder_lstm2 = LSTM(HIDDEN_DIM, \n",
    "                    return_sequences = True,\n",
    "                    return_state = True, \n",
    "                    dropout = 0.4, \n",
    "                    recurrent_dropout = 0.4)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(HIDDEN_DIM, \n",
    "                    return_sequences = True,\n",
    "                    return_state = True, \n",
    "                    dropout = 0.4, \n",
    "                    recurrent_dropout = 0.4)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output1)\n",
    "\n",
    "#now set up the decoder using the encoder_states as the initial decoder state\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "#Embedding layer\n",
    "dec_emb_layer = Embedding(input_dim = VOCAB_SIZE,\n",
    "                    output_dim = EMBEDDING_DIM,\n",
    "                    trainable = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "#Decoder LSTM\n",
    "decoder_lstm = LSTM(HIDDEN_DIM, \n",
    "                   return_sequences = True, \n",
    "                   return_state = True, \n",
    "                   dropout = 0.4, \n",
    "                   recurrent_dropout = 0.2)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(VOCAB_SIZE, activation = 'softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "loose-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy')\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor = 'loss', mode = 'min', verbose =1, patience =2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "introductory-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split up the data for training and testing\n",
    "factors_train, factors_test, expansions_train, expansions_test = train_test_split(factors_padded, expansions_padded, test_size =0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "essential-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "determined-trigger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 29s 3s/step - loss: 3.1264\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 23s 3s/step - loss: 1.9427\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.7236\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.6475\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.6202\n"
     ]
    }
   ],
   "source": [
    "#now let's train the model- pass the factors and expanded sequences, excluding the last character in the expanded sequences as input\n",
    "#as output pass a re-shaped expansions tensor composed of every character in the expansions from the 2nd index onwards\n",
    "history = model.fit([factors_train, expansions_train[:,:-1]],\n",
    "                   expansions_train.reshape(expansions_train.shape[0], expansions_train.shape[1],1)[:,1:],\n",
    "                   epochs = EPOCHS, \n",
    "                   batch_size = BATCH_SIZE, \n",
    "                   callbacks = [es], \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "unlike-grave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "understanding-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "impressive-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model for good measure\n",
    "model.save('seq2seq_2_trained.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-perception",
   "metadata": {},
   "source": [
    "### Now define the encoder/decoder inference model\n",
    "\n",
    "To accept an input factored sequence and return a predicted expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "elder-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = [encoder_outputs, state_h, state_c])\n",
    "\n",
    "#decoder setup\n",
    "#below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(HIDDEN_DIM, ))\n",
    "decoder_state_input_c = Input(shape=(HIDDEN_DIM, ))\n",
    "decoder_hidden_state_input = Input(shape=(MAX_LEN, HIDDEN_DIM))\n",
    "\n",
    "#get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# to predict the next character in the sequence, set the initial states\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#a dense softmax layer to generate the probability distribution over the target vocab\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "#the final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "separate-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now define a function which accepts the input text and outputs the predicted expansion\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    #encode the input as state vectors\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    #populate the first character of the target sequence with the beginning of sequence tag\n",
    "    target_seq[0,0] = word2idx['<bos>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sequence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([target_seq]+[e_out, e_h, e_c])\n",
    "        \n",
    "        #sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0,-1,:])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if sampled_token_index!= '<eos>':\n",
    "            decoded_sequence +=',' + sampled_token\n",
    "            \n",
    "        #the exit condition is either hitting the max length or finding a stop word\n",
    "        if sampled_token == '<eos>' or len(decoded_sequence.split(\",\"))>=MAX_LEN-1:\n",
    "            stop_condition = True\n",
    "            \n",
    "        #update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        #update the internal states\n",
    "        (e_h, e_c) = (h,c)\n",
    "        \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "neutral-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now define the functions that will convert between numeric and string representations\n",
    "#make sure to define the target character index\n",
    "\n",
    "#recal that we already have dictionaries holding the word2idx and idx2word values\n",
    "\n",
    "#from sequence to expansion\n",
    "def seq2exp(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != word2idx['<eos>'] and i != word2idx['<bos>']:\n",
    "            newString = newString + idx2word[i] + ','\n",
    "            \n",
    "    return newString\n",
    "\n",
    "#from expansion to sequence\n",
    "\n",
    "def exp2seq(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + word2idx[i] + ','\n",
    "            \n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "compatible-inclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor: (,-,5,*,c,-,1,1,),*,(,c,+,1,2,),\n",
      "Original expansion: -,5,*,c,*,*,2,-,7,1,*,c,-,1,3,2,\n",
      "1/1 [==============================] - 0s 377ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Exception encountered when calling layer \"model_7\" (type Functional).\n    \n    Layer \"lstm_7\" expects 5 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'model_7/embedding_3/embedding_lookup/Identity_1:0' shape=(None, 1, 10) dtype=float32>]\n    \n    Call arguments received by layer \"model_7\" (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 1), dtype=float32)', 'tf.Tensor(shape=(None, 29, 300), dtype=float32)', 'tf.Tensor(shape=(None, 300), dtype=float32)', 'tf.Tensor(shape=(None, 300), dtype=float32)')\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f2046ca21b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Factor:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactors_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Original expansion:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpansions_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     print ('Predicted expansion:', decode_sequence(factors_train[i].reshape(1,\n\u001b[0m\u001b[1;32m      7\u001b[0m            MAX_LEN)))\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-e7b66b329624>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Exception encountered when calling layer \"model_7\" (type Functional).\n    \n    Layer \"lstm_7\" expects 5 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'model_7/embedding_3/embedding_lookup/Identity_1:0' shape=(None, 1, 10) dtype=float32>]\n    \n    Call arguments received by layer \"model_7\" (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 1), dtype=float32)', 'tf.Tensor(shape=(None, 29, 300), dtype=float32)', 'tf.Tensor(shape=(None, 300), dtype=float32)', 'tf.Tensor(shape=(None, 300), dtype=float32)')\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "#now lets generate some predictions\n",
    "\n",
    "for i in range(0, 19):\n",
    "    print ('Factor:', seq2exp(factors_train[i]))\n",
    "    print ('Original expansion:', seq2exp(expansions_train[i]))\n",
    "    print ('Predicted expansion:', decode_sequence(factors_train[i].reshape(1,\n",
    "           MAX_LEN)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-smooth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
